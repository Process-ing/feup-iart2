{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9444027e",
   "metadata": {},
   "source": [
    "# üéí Backpack Prediction Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23c3b2",
   "metadata": {},
   "source": [
    "**FEUP 2024/2025 - L.EIC029 IART**\n",
    "\n",
    "- Bruno Oliveira - 202208700  \n",
    "- Henrique Fernandes - 202204988  \n",
    "- Rodrigo Coelho - 202205188  \n",
    "\n",
    "> Based on Kaggle Playground Season 5, Episode 2  \n",
    "> April 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f7e55",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc24c1",
   "metadata": {},
   "source": [
    "This project is related to the application of Supervised Learning techniques to real world problems. Specifically, we will develop and evaluate machine learning models that accurately predict the price of student backpacks (target variable), based on a variety of input attributes.\n",
    "\n",
    "For this we will use a labeled dataset from Kaggle which contains different bag characteristics and we want to understand how they influence the price.\n",
    "\n",
    "[Link to Backpack Prediction Challenge](https://www.kaggle.com/competitions/playground-series-s5e2/data)\n",
    "\n",
    "We will follow the machine learning pipeline: data preprocessing, problem definition and target identification, model selection and parameter tuning, model training and testing, and result evaluation and comparison.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ada01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è Project setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58250201",
   "metadata": {},
   "source": [
    "### üì¶ Virtual Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f96d599",
   "metadata": {},
   "source": [
    "In order to setup the project, use the following commands to setup a virtual environment and install the needed dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv .venv\n",
    "!source .venv/bin/activate\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176dfa6d",
   "metadata": {},
   "source": [
    "Once the dependencies are installed, the script below can be used to download the dataset from the Kaggle competition, using your Kaggle account.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Don't forget to download the Kaggle token associated with your account from the <a href=\"https://www.kaggle.com/settings\">Settings page</a>, move it to the current folder and join the <a href=\"https://www.kaggle.com/competitions/playground-series-s5e2/\">Kaggle playground competition</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa775246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "dataset_zip = data_dir.joinpath(\"playground-series-s5e2.zip\")\n",
    "dataset_train = data_dir.joinpath(\"train.csv\")\n",
    "dataset_extra = data_dir.joinpath(\"training_extra.csv\")\n",
    "\n",
    "if not dataset_train.exists() or not dataset_extra.exists():\n",
    "    if not dataset_zip.exists():\n",
    "        print(\"Dataset zip not found. Downloading from Kaggle...\")\n",
    "        !kaggle competitions download -c playground-series-s5e2\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(\"Dataset zip already exists.\")\n",
    "\n",
    "    print(\"Unzipping the dataset...\")\n",
    "    !unzip -o playground-series-s5e2.zip -d data\n",
    "    !rm playground-series-s5e2.zip\n",
    "else:\n",
    "    print(\"Dataset already exists. Skipping download and extraction.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999020a2",
   "metadata": {},
   "source": [
    "### üìÇ Loading the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de05a04",
   "metadata": {},
   "source": [
    "With the dependencies met and having downloaded the dataset, we can now load it into our environment.  \n",
    "The following commands will load the `train.csv` dataset which contains 300000 entries and is used to train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(dataset_train)\n",
    "\n",
    "data.info()\n",
    "\n",
    "print(\"\\nFirst 3 rows of the dataset:\")\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce4640",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## üîç Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911decd4",
   "metadata": {},
   "source": [
    "### üåê Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e27fb",
   "metadata": {},
   "source": [
    "As mentioned before, the training dataset consists of *300000* **rows** of data related to *9* **backpack features** and the **price** (target variable). \n",
    "\n",
    "Most of these features are **categorical** (brand, material, size, laptop compartment, waterproof, style and color) while the others are **numerical** (compartments and weight capacity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview_data(data, title):\n",
    "    print(title)\n",
    "    data_shape = data.shape\n",
    "    print(f\"\\nNumber of rows: {data_shape[0]}\")\n",
    "    print(f\"Number of columns: {data_shape[1]}\")\n",
    "    print(\"\\nData types of each column:\")\n",
    "    print(data.dtypes)\n",
    "\n",
    "overview_data(data, \"Training Dataset Overview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97e267",
   "metadata": {},
   "source": [
    "### ‚ùì Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f33ddc",
   "metadata": {},
   "source": [
    "Although the challenge states that the training dataset was generated from a deep learning model trained on another dataset, most of the features include some missing values which were probably introduced to challenge the data preprocessing.\n",
    "\n",
    "The percentage of **missing values for each feature is below 3.5%** and the **overall percentage of rows with at least one missing value is less than 18%** of the entire training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be864bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = pd.DataFrame({\n",
    "    'Column': data.columns,\n",
    "    'Missing Train Values': data.isnull().sum().values,\n",
    "    'Percentage of Missing Train Values': data.isnull().sum().values / len(data) * 100\n",
    "})\n",
    "\n",
    "missing_values = missing_values[~missing_values['Column'].isin(['id', 'Price'])]\n",
    "\n",
    "summary_row = pd.DataFrame([{\n",
    "    'Column': 'Rows with Missing Values',\n",
    "    'Missing Train Values': data.isnull().any(axis=1).sum(),\n",
    "    'Percentage of Missing Train Values': data.isnull().any(axis=1).sum() / len(data) * 100\n",
    "}])\n",
    "\n",
    "missing_values = pd.concat([missing_values, summary_row], ignore_index=True)\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259fcdd",
   "metadata": {},
   "source": [
    "### üß¨ Duplicated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d661d",
   "metadata": {},
   "source": [
    "Despite having a moderate amount of missing data, there are no duplicated rows in the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_duplicates = data.drop('id', axis=1).duplicated().sum()\n",
    "print(f\"Data duplicates: {data_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddadd5",
   "metadata": {},
   "source": [
    "### üßÆ Distribution of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0ff56",
   "metadata": {},
   "source": [
    "When it comes to data distribution, most columns follow a relatively constant distribution without any major outliers or imbalances. While each categorical feature has a (slightly) dominant category, there are no significant discrepancies in the frequency of each value. This is also true for the numeric columns, where the distribution of value counts remains approximately the same or oscillates between an average value.\n",
    "\n",
    "However, for the target variable (Price), there is a noticeable spike in the count at the maximum value, suggesting that values larger than this might have been truncated or capped. This could be an important consideration when modeling, as it might affect the model's results, especially when predicting higher-price items.\n",
    "\n",
    "The other features' graphs do not indicate any major skewness, meaning the dataset seems well-suited for classification of all types of backpacks, with no specific bias introduced by the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "categorical_columns = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "numerical_columns = ['Compartments', 'Weight Capacity (kg)', 'Price']\n",
    "\n",
    "FIGURE_WIDTH = 18\n",
    "PLOTS_PER_ROW = 3\n",
    "\n",
    "def plot_categorical_columns(df):\n",
    "    num_columns = len(categorical_columns)\n",
    "    num_rows = math.ceil(num_columns / PLOTS_PER_ROW)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, PLOTS_PER_ROW, figsize=(FIGURE_WIDTH, FIGURE_WIDTH / PLOTS_PER_ROW * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(categorical_columns):\n",
    "        sns.countplot(data=df, x=column, order=df[column].value_counts().index, ax=axes[i])\n",
    "        axes[i].set_title(f\"Distribution of {column}\")\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_numeric_columns(df):\n",
    "    num_columns = len(numerical_columns)\n",
    "    num_rows = math.ceil(num_columns / PLOTS_PER_ROW)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, PLOTS_PER_ROW, figsize=(FIGURE_WIDTH, FIGURE_WIDTH / PLOTS_PER_ROW * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(numerical_columns):\n",
    "        sns.histplot(df[column], ax=axes[i], discrete=column == 'Compartments')\n",
    "        axes[i].set_title(f\"Distribution of {column}\")\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_categorical_columns(data)\n",
    "plot_numeric_columns(data)\n",
    "\n",
    "data.drop('id', axis=1).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4893593",
   "metadata": {},
   "source": [
    "### üîó Data Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af21830",
   "metadata": {},
   "source": [
    "The correlation analysis revealed that no strong linear relationships appear to exist between the columns that could influence the target variable and, consequently, the model training.\n",
    "\n",
    "As it can be seen both from the Categorical vs. Categorical countplots, there are no major correlations between different categorical features of the dataset. A similar conclusion can be taken from the correlation heatmap of the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5082b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_WIDTH = 20\n",
    "PLOTS_PER_ROW = 3\n",
    "\n",
    "def plot_categorical_corr(df):\n",
    "    num_columns = (len(categorical_columns) * (len(categorical_columns) - 1)) // 2\n",
    "    num_rows = math.ceil(num_columns / PLOTS_PER_ROW)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, PLOTS_PER_ROW, figsize=(FIGURE_WIDTH, FIGURE_WIDTH / PLOTS_PER_ROW * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    plot_idx = 0\n",
    "    for i in range(len(categorical_columns)):\n",
    "        for j in range(i + 1, len(categorical_columns)):\n",
    "            sns.countplot(x=categorical_columns[i], hue=categorical_columns[j], data=data, ax=axes[plot_idx])\n",
    "            axes[plot_idx].set_title(f\"Correlation of {categorical_columns[i]} with {categorical_columns[j]}\")\n",
    "            axes[plot_idx].tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better readability\n",
    "            plot_idx += 1\n",
    "\n",
    "    for j in range(plot_idx, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_numeric_corr(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(data[[col for col in numerical_columns if col != 'Price']].corr(), annot=True, cmap='coolwarm', fmt=\".3f\", cbar=True)\n",
    "    plt.title(f\"Numeric Column Correlation Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "plot_categorical_corr(data)\n",
    "plot_numeric_corr(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845910e8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßπ Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57265830",
   "metadata": {},
   "source": [
    "### üß© Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148bb0f",
   "metadata": {},
   "source": [
    "As seen in the previous section, the training datasets contains missing values in most of the columns. To deal with this, data imputation is applied using the following methods:\n",
    "\n",
    "- For **categorical features**: we will use the mode of the values because it preserves the most common category without introducing new values.\n",
    "- For **numeric features**: we will use the median of the values because it is a reliable (better than using the mean) measure of the central tendency, reducing the influence of possible outliers or anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(df):\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    for col in numerical_columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "impute_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47304b90",
   "metadata": {},
   "source": [
    "### üè∑Ô∏è Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb65548",
   "metadata": {},
   "source": [
    "To facilitate the modelling step, categorical features must also be encoded into numeric features that the machine learning algorithms can use. For the data encoding we used the following methods:\n",
    "\n",
    "- **Label Encoding**: for columns Brand, Color, Material and Style, we assign codes to each of the original categories (since there is no implicit ordering)\n",
    "- **Ordinal Mapping**: for the Size feature, we manually map the existing categories into numbers, preserving the natural size ordering\n",
    "- **Binary Mapping**: for Laptop Compartment and Waterproof, we map the boolean values into integers (1 for Yes and 0 for No)\n",
    "\n",
    "All of the new columns have slightly different names to be distinguishable from the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['IBrand', 'IMaterial', 'ISize', 'Has_Laptop_Compartment', 'Is_Waterproof', 'IStyle', 'IColor']\n",
    "\n",
    "def encode_data(df):\n",
    "    for col in ['Brand', 'Material', 'Style', 'Color']:\n",
    "        df['I' + col] = df[col].astype('category').cat.codes\n",
    "\n",
    "    df['ISize'] = df['Size'].map({'Small': 1, 'Medium': 2, 'Large': 3})\n",
    "\n",
    "    df['Has_Laptop_Compartment'] = df['Laptop Compartment'].map({'Yes': 1, 'No': 0})\n",
    "    df['Is_Waterproof'] = df['Waterproof'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "encode_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a3203",
   "metadata": {},
   "source": [
    "### ‚öñÔ∏è Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f014a",
   "metadata": {},
   "source": [
    "A final step of the data preprocessing is the normalization of the numerical features to ensure that these columns have a comparable scale. In our dataset, this is the case for the Weight Capacity, whose feature can now be seen in the `Weight_Capacity_Ratio`. This ratio was obtained by dividing all values by the maximum value, creating a range of [0,1].\n",
    "\n",
    "This reduces the risk of values of larger magnitude disproportionately influencing the models, while preserving the distribution and relative values of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns += ['Weight_Capacity_Ratio']\n",
    "\n",
    "def normalize_data(df):\n",
    "    df['Weight_Capacity_Ratio'] = df['Weight Capacity (kg)'] / df['Weight Capacity (kg)'].max()\n",
    "\n",
    "normalize_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147cadd",
   "metadata": {},
   "source": [
    "### üéØ Target Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592038cf",
   "metadata": {},
   "source": [
    "To conclude the data preprocessing, we will also define final columns of the dataset that will be used to train the models, as well as the target variable (Price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9db1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = new_columns + ['Compartments']\n",
    "\n",
    "X = data[final_columns]\n",
    "y = data['Price']\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b9756",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## üõ†Ô∏è Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049ffd3",
   "metadata": {},
   "source": [
    "### üéõÔ∏è Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb62ca",
   "metadata": {},
   "source": [
    "Before moving on to the models themselves, it's important to set up the function that will determine the best parameters for a specific model for the given problem. \n",
    "\n",
    "For this we used **Grid Search with K-Fold Cross Validation** to find the parameters that reduce the prediction error.  \n",
    "Based on the original challenge, we also used the **negative mean squared error** as the **scoring metric**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "def tune_params(model, param_grid, X, y, cv=10):\n",
    "    cv = KFold(n_splits=cv, shuffle=True, random_state=1)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    print(f\"Best parameters:\")\n",
    "    for param_name, param_value in grid_search.best_params_.items():\n",
    "        print(f\"  {param_name}: {param_value}\")\n",
    "\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8ea09",
   "metadata": {},
   "source": [
    "### üìë Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16d4bf",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of the models, K-Fold Cross Validation will also be used. For each train-test fold, the following metrics are used for analysis:\n",
    "\n",
    "- **Mean Squared Error**: average square difference between predicted and actual value\n",
    "- **Root Mean Squared Error**: more interpretable scale of previous metric\n",
    "- **Mean Absolute Error**: average of the absolute difference between predicted and actual value\n",
    "- **R¬≤ Score**: proportion of variance in the target variable explained by the model (remaining is noise or unexplained variance)\n",
    "\n",
    "Additionally, the total **training time** and **testing time** are also measured and used for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_regressor(model, X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=1)\n",
    "\n",
    "    mse_scores = []\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "    training_times = []\n",
    "    testing_times = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end_train = time.time()\n",
    "        training_times.append(end_train - start_train)\n",
    "\n",
    "        start_test = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_test = time.time()\n",
    "        testing_times.append(end_test - start_test)\n",
    "\n",
    "        mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "        \n",
    "        print(f\"Trained model in {training_times[-1]:.4f} seconds and tested in {testing_times[-1]:.4f} seconds.\")\n",
    "        \n",
    "    print(f\"Avg Mean Squared Error (MSE): {np.mean(mse_scores):.4f}\")\n",
    "    print(f\"Avg Root Mean Squared Error (RMSE): {np.sqrt(np.mean(mse_scores)):.4f}\")\n",
    "    print(f\"Avg Mean Absolute Error (MAE): {np.mean(mae_scores):.4f}\")\n",
    "    print(f\"Avg R¬≤ Score: {np.mean(r2_scores):.4f}\")\n",
    "    print(f\"Avg Training Time: {np.mean(training_times):.4f} seconds\")\n",
    "    print(f\"Avg Testing Time: {np.mean(testing_times):.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c770dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_eval(model, param_grid, X, y):\n",
    "    print(f\"Tuning parameters for {model.__class__.__name__}...\")\n",
    "    best_params = tune_params(model, param_grid, X, y)\n",
    "    model.set_params(**best_params)\n",
    "\n",
    "    print()\n",
    "    print(f\"Evaluating {model.__class__.__name__} with best parameters...\")\n",
    "    evaluate_regressor(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff74342d",
   "metadata": {},
   "source": [
    "### üå≤ Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd90ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=1)\n",
    "param_grid = {\n",
    "    'criterion': ['squared_error', 'friedman_mse'],\n",
    "    'max_depth': [1, 2, 3, 4, 5, None],\n",
    "    'max_features': [1, 2, 3, 5, None],\n",
    "}\n",
    "\n",
    "tune_and_eval(model, param_grid, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c928f3",
   "metadata": {},
   "source": [
    "### üßë‚Äçü§ù‚Äçüßë K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 10, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2] # 1 -> manhattan; 2 -> euclidean\n",
    "}\n",
    "\n",
    "X_sample = X.sample(30000, random_state=1)\n",
    "y_sample = y.loc[X_sample.index]\n",
    "\n",
    "tune_and_eval(model, param_grid, X_sample, y_sample)\n",
    "# tune_and_eval(model, param_grid, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ed4b7d",
   "metadata": {},
   "source": [
    "### ‚õîÔ∏è Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b18f9",
   "metadata": {},
   "source": [
    "### üß† Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9a2dc",
   "metadata": {},
   "source": [
    "### üé≤ Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import export_graphviz\n",
    "# from sklearn import tree\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.tree import plot_tree\n",
    "# plt.figure(figsize=(100, 20))\n",
    "# plot_tree(model, filled=True, feature_names=X.columns, fontsize=10, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all the values from hte Brand column\n",
    "# brand_values = train_data['Brand'].unique()\n",
    "# # get average price per brand\n",
    "# avg_price_per_brand = train_data.groupby('Brand')['Price'].mean().sort_values(ascending=False)\n",
    "# avg_price_per_brand\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
