{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9444027e",
   "metadata": {},
   "source": [
    "# Backpack Prediction Challenge\n",
    "\n",
    "**FEUP 2024/2025 - L.EIC029 IART**\n",
    "\n",
    "- Bruno Oliveira - 202208700  \n",
    "- Henrique Fernandes - 202204988  \n",
    "- Rodrigo Coelho - 202205188  \n",
    "\n",
    "> Based on Kaggle Playground Season 5, Episode 2  \n",
    "> April 2025\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup\n",
    "\n",
    "### Virtual Environment\n",
    "\n",
    "In order to setup the project, use the following commands to setup a virtual environment and install the needed dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv .venv\n",
    "!source .venv/bin/activate\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176dfa6d",
   "metadata": {},
   "source": [
    "Once the dependencies are installed, the script below can be used to download the dataset from the Kaggle competition, using your Kaggle account.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Don't forget to download the Kaggle token associated with your account from the <a href=\"https://www.kaggle.com/settings\">Settings page</a>, move it to the current folder and join the <a href=\"https://www.kaggle.com/competitions/playground-series-s5e2/\">Kaggle playground competition</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8184f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "\n",
    "!kaggle competitions download -c playground-series-s5e2\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "!mv playground-series-s5e2.zip data/\n",
    "os.chdir(data_dir)\n",
    "!unzip -o playground-series-s5e2.zipnd-series-s5e2.zip\n",
    "!rm playground-series-s5e2.zip\n",
    "!ls -lh\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Datasets\n",
    "\n",
    "With the dependencies met and having downloaded the dataset, we can now load it into our environment. The following commands wil load boat of the datasets:\n",
    "\n",
    "- `train.csv` which contains 300000 entries and is used to train the models\n",
    "- `test.csv` which contains 200000 entries and is used to test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_data.info()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab00cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_train = pd.DataFrame({\n",
    "    'Column': train_data.columns,\n",
    "    'Missing Train Values': train_data.isnull().sum().values,\n",
    "    'Percentage of Missing Train Values': train_data.isnull().sum().values / len(train_data) * 100\n",
    "})\n",
    "\n",
    "missing_values_test = pd.DataFrame({\n",
    "    'Column': test_data.columns,\n",
    "    'Missing Test Values': test_data.isnull().sum().values,\n",
    "    'Percentage of Missing Test Values': test_data.isnull().sum().values / len(test_data) * 100\n",
    "})\n",
    "\n",
    "merged_missing_values = pd.merge(missing_values_train, missing_values_test, on='Column', how='outer')\n",
    "merged_missing_values = merged_missing_values[~merged_missing_values['Column'].isin(['id', 'Price'])]\n",
    "merged_missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259fcdd",
   "metadata": {},
   "source": [
    "Duplicated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_duplicates = train_data.drop('id', axis=1).duplicated().sum()\n",
    "test_data_duplicates = test_data.drop('id', axis=1).duplicated().sum()\n",
    "print(f\"Train data duplicates: {train_data_duplicates}\")\n",
    "print(f\"Test data duplicates: {test_data_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e83d67",
   "metadata": {},
   "source": [
    "Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1794664",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddadd5",
   "metadata": {},
   "source": [
    "Distribution of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_text_columns(data, columns):\n",
    "    for column in columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data[column], order=data[column].value_counts().index)\n",
    "        plt.title(f\"Distribution of {column}\")\n",
    "        plt.show()\n",
    "\n",
    "def plot_numeric_columns(data, columns):\n",
    "    for column in columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data[column], bins=30)\n",
    "        plt.title(f\"Distribution of {column}\")\n",
    "        plt.show()\n",
    "        \n",
    "def plot_pairplot(data, column1, column2):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.pairplot(data[['Brand', 'Material', 'Price']], hue='Brand')\n",
    "    plt.title(f\"Scatter plot of {column1} vs {column2}\")\n",
    "    plt.show()\n",
    "        \n",
    "# plot_text_columns(train_data, train_data.columns[train_data.dtypes == 'object'].tolist())\n",
    "# plot_numeric_columns(train_data, [col for col in train_data.columns if col != 'id' and train_data[col].dtypes != 'object'])\n",
    "plot_pairplot(train_data, 'Brand', 'Material')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4893593",
   "metadata": {},
   "source": [
    "Data Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "numeric_cols = ['Brand', 'Material', 'Price']\n",
    "\n",
    "df_numeric = train_data[numeric_cols].dropna()\n",
    "\n",
    "sns.pairplot(df_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical features and define features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9db1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_data.dropna(inplace=True)\n",
    "label_encoders = {}\n",
    "for col in ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "X = train_data.drop('Price', axis=1)\n",
    "y = train_data['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd90ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=1, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {mse**0.5:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(100, 20))\n",
    "plot_tree(model, filled=True, feature_names=X.columns, fontsize=10, max_depth=5)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the values from hte Brand column\n",
    "brand_values = train_data['Brand'].unique()\n",
    "# get average price per brand\n",
    "avg_price_per_brand = train_data.groupby('Brand')['Price'].mean().sort_values(ascending=False)\n",
    "avg_price_per_brand\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
